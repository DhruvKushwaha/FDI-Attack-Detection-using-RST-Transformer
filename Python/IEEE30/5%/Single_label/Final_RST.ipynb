{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "# Import transformer model\n",
    "from Transformer_Archs.RST_Enc import TimeseriesTransformer\n",
    "\n",
    "# Clear CUDA cache\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option for 5% or 10% attack data\n",
    "option = '5' \n",
    "\n",
    "# Get data loaders\n",
    "train_dataset = torch.load('./Preprocessed_data/train_dataset_{}.pt'.format(option), weights_only=False)\n",
    "train_config = torch.load('./Preprocessed_data/train_config_{}.pt'.format(option), weights_only=False)\n",
    "train_loader = DataLoader(train_dataset, **train_config)\n",
    "\n",
    "val_dataset = torch.load('./Preprocessed_data/val_dataset_{}.pt'.format(option), weights_only=False)\n",
    "val_config = torch.load('./Preprocessed_data/val_config_{}.pt'.format(option), weights_only=False)\n",
    "val_loader = DataLoader(val_dataset, **val_config)\n",
    "\n",
    "test_dataset = torch.load('./Preprocessed_data/test_dataset_{}.pt'.format(option), weights_only=False)\n",
    "test_config = torch.load('./Preprocessed_data/test_config_{}.pt'.format(option), weights_only=False)\n",
    "test_loader = DataLoader(test_dataset, **test_config)\n",
    "\n",
    "# Set feautures and target size\n",
    "num_features = 86\n",
    "out_features = 11\n",
    "seq_len = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sparsemax hyperparameter\n",
    "alpha = 2 # must be greater than 1\n",
    "\n",
    "# Setup hyperparameter\n",
    "d_model = 64\n",
    "nhead = 4\n",
    "num_encoder_layers = 2\n",
    "dim_feedforward = 64\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Initialize the model\n",
    "# Input style: [input_feature_size, output_feature_size, d_model, nhead, num_encoder_layers, dim_feedforward]\n",
    "model = TimeseriesTransformer(num_features, out_features, d_model, nhead, num_encoder_layers, dim_feedforward, alpha).to(device)\n",
    "\n",
    "# Training loop (simplified)\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr= 1e-4) #0.001, 5e-4, 1e-3\n",
    "\n",
    "# Define the learning rate scheduler (for example, exponential decay)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, min_delta=0):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How many epochs to wait after last time validation loss improved.\n",
    "            min_delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.best_loss = None\n",
    "        self.counter = 0\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "        elif val_loss > self.best_loss - self.min_delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    correct= 0\n",
    "    accuracy_list, loss_list = [], []\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.type(torch.LongTensor).to(device)\n",
    "        data = data.permute(1, 0, 2)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        correct = pred.eq(target.view_as(pred)).sum().item()\n",
    "        accuracy = correct / target.shape[0]\n",
    "        accuracy_list.append(accuracy)\n",
    "        loss_list.append(loss.item())\n",
    "        \n",
    "    print(\"Train Epoch: {} - Training Loss: {:.5f} Training accuracy: {:.3f}%\".format(epoch,np.mean(loss_list) ,np.mean(accuracy_list)*100))\n",
    "\n",
    "    return np.mean(accuracy_list)*100, np.mean(loss_list)\n",
    "\n",
    "def Validation(model, device, valid_loader, epoch):\n",
    "    model.eval()\n",
    "    correct= 0\n",
    "    accuracy_list, loss_list = [], []\n",
    "    for batch_idx, (data, target) in enumerate(valid_loader):\n",
    "        data, target = data.to(device), target.type(torch.LongTensor).to(device)\n",
    "        data = data.permute(1, 0, 2)\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        correct = pred.eq(target.view_as(pred)).sum().item()\n",
    "        accuracy = correct / target.shape[0]\n",
    "        accuracy_list.append(accuracy)\n",
    "        loss_list.append(loss.item())\n",
    "        \n",
    "    print(\"Valid Epoch: {} - Validation Loss: {:.5f} Validation accuracy: {:.3f}%\".format(epoch,np.mean(loss_list) ,np.mean(accuracy_list)*100))\n",
    "\n",
    "    return np.mean(accuracy_list)*100, np.mean(loss_list)             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the early stopping mechanism\n",
    "early_stopping = EarlyStopping(patience=10, min_delta=0.0001)\n",
    "train_acc_list, val_acc_list = [], []\n",
    "train_loss_list, val_loss_list = [], []\n",
    "\n",
    "epochs = 70\n",
    "for epoch in range(1, epochs + 1):\n",
    "        train_acc, train_loss = train( model, device, train_loader, optimizer, epoch)\n",
    "        Val_acc, Val_loss = Validation(model, device, val_loader, epoch)\n",
    "        train_acc_list.append(train_acc), val_acc_list.append(Val_acc)\n",
    "        train_loss_list.append(train_loss), val_loss_list.append(Val_loss)\n",
    "        scheduler.step(train_loss)\n",
    "        early_stopping(train_loss)\n",
    "        if early_stopping.early_stop:\n",
    "             print(\"Early stopping triggered. Stopping training.\")\n",
    "             break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save training loss and accuracy\n",
    "np.save('./Final_models/RST/train_loss_RST_{}.npy'.format(option), np.array(train_loss_list))\n",
    "np.save('./Final_models/RST/train_accuracy_RST_{}.npy'.format(option), np.array(train_acc_list))\n",
    "np.save('./Final_models//RST/val_loss_RST_{}.npy'.format(option), np.array(val_loss_list))\n",
    "np.save('./Final_models/RST/val_accuracy_RST_{}.npy'.format(option), np.array(val_acc_list))\n",
    "torch.save(model.state_dict(), \"./Final_models/RST/transformer_RST_{}.pth\".format(option))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sparsemax hyperparameter\n",
    "alpha = 2 # must be greater than 1\n",
    "\n",
    "# Setup hyperparameter\n",
    "d_model = 64\n",
    "nhead = 4\n",
    "num_encoder_layers = 2\n",
    "dim_feedforward = 64\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Initialize the model\n",
    "model = TimeseriesTransformer(num_features, out_features,d_model, nhead, num_encoder_layers,dim_feedforward,alpha).to(device)\n",
    "\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr= 1e-4) \n",
    "\n",
    "# Load model weights\n",
    "model.load_state_dict(torch.load(\"./Final_models/RST/transformer_RST_{}.pth\".format(option), weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "accuracy_list = []\n",
    "with torch.no_grad():\n",
    "    data, target = next(iter(test_loader))\n",
    "    data, target = data.to(device), target.type(torch.LongTensor).to(device)\n",
    "    data = data.permute(1, 0, 2)\n",
    "    output = model(data)\n",
    "    test_loss += criterion(output, target).item()  # sum up batch loss\n",
    "    pred = output.argmax(dim=1, keepdim=True)\n",
    "    correct = pred.eq(target.view_as(pred)).sum().item()\n",
    "    accuracy = correct / target.shape[0]\n",
    "    accuracy_list.append(accuracy)\n",
    "\n",
    "    print('Test set: Loss: {:.6f}, Accuracy: {:.3f}%, Correct: [{:.0f}/{:.0f}]\\n'.format(\n",
    "        test_loss, accuracy*100, correct, data.size(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(target.cpu().numpy(), output.argmax(dim=1, keepdim=True).cpu().numpy())\n",
    "\n",
    "#plot confusion matrix\n",
    "plt.figure(figsize=(15, 12))\n",
    "sns.heatmap(cm, annot=True, fmt='g')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')\n",
    "plt.title('Confusion matrix for RST Transformer')\n",
    "plt.xticks(ticks=[0.5, 1.5, 2.5, 3.5, 4.5, 5.5, 6.5, 7.5, 8.5, 9.5, 10.5], labels=['No Attack','Attack_Bus_15','Attack_Bus_18','Attack_Bus_19',\n",
    "                                      'Attack_Bus_20','Attack_Bus_21', 'Attack_Bus_23',\n",
    "                                      'Attack_Bus_24','Attack_Bus_26','Attack_Bus_29',\n",
    "                                      'Attack_Bus_30'])\n",
    "plt.yticks(ticks=[0.5, 1.5, 2.5, 3.5, 4.5, 5.5, 6.5, 7.5, 8.5, 9.5, 10.5], labels=['No Attack','Attack_Bus_15','Attack_Bus_18','Attack_Bus_19',\n",
    "                                      'Attack_Bus_20','Attack_Bus_21', 'Attack_Bus_23',\n",
    "                                      'Attack_Bus_24','Attack_Bus_26','Attack_Bus_29',\n",
    "                                      'Attack_Bus_30'])\n",
    "plt.savefig('Final_models/RST_confusion_matrix_{}.png'.format(option), dpi=500, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(target.cpu().numpy(), output.argmax(dim=1, keepdim=True).cpu().numpy(), zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# False positive rate\n",
    "fp = cm.sum(axis=0) - np.diag(cm)\n",
    "fn = cm.sum(axis=1) - np.diag(cm)\n",
    "tp = np.diag(cm)\n",
    "tn = cm.sum() - (fp + fn + tp)\n",
    "\n",
    "fpr = fp/(fp + tn)\n",
    "print(\"False Positive Rate\\n No Attack: {:.3f}%, Bus15: {:.3f}%, Bus18: {:.3f}%, Bus19: {:.3f}%, Bus20: {:.3f}%, Bus21: {:.3f}%, \"\n",
    "\"Bus23: {:.3f}%, Bus24: {:.3f}%, Bus26: {:.3f}%, Bus29: {:.3f}%,Bus30: {:.3f}%\".format(fpr[0]*100,\n",
    "                                                        fpr[1]*100,fpr[2]*100, fpr[3]*100, fpr[4]*100, fpr[5]*100, fpr[6]*100, fpr[7]*100, fpr[8]*100, fpr[9]*100, fpr[10]*100))\n",
    "\n",
    "# False negative rate\n",
    "fnr = fn/(fn + tp)\n",
    "print(\"False Negative Rate\\n No Attack: {:.3f}%, Bus15: {:.3f}%, Bus18: {:.3f}%, Bus19: {:.3f}%, Bus20: {:.3f}%, Bus21: {:.3f}%, \"\n",
    "\"Bus23: {:.3f}%, Bus24: {:.3f}%, Bus26: {:.3f}%, Bus29: {:.3f}%,Bus30: {:.3f}%\".format(fnr[0]*100,\n",
    "                                                        fnr[1]*100,fnr[2]*100, fnr[3]*100, fnr[4]*100, fnr[5]*100, fnr[6]*100, fnr[7]*100, fnr[8]*100, fnr[9]*100, fnr[10]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot avg accuracy and loss\n",
    "plt.grid()\n",
    "plt.plot(train_acc_list, label=r\"Training accuracy\")\n",
    "plt.plot(val_acc_list, label=r\"Validation accuracy\")\n",
    "plt.xlabel(r\"Epoch $\\longrightarrow$\")\n",
    "plt.ylabel(r\"Accuracy $\\longrightarrow$\");\n",
    "plt.legend(loc='best')\n",
    "plt.title(r\"Average accuracy per epoch - RST\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot avg loss\n",
    "plt.grid()\n",
    "plt.plot(train_loss_list, label=r\"Training loss\")\n",
    "plt.plot(val_loss_list, label=r\"Validation loss\")\n",
    "plt.xlabel(r\"Epoch $\\longrightarrow$\")\n",
    "plt.ylabel(r\"Loss $\\longrightarrow$\");\n",
    "plt.legend(loc='best');\n",
    "plt.title(r\"Average loss per epoch - RST\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
