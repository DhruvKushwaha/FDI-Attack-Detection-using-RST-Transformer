{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "from torchmetrics.classification import BinaryAccuracy, BinaryAveragePrecision, BinaryF1Score, BinaryPrecision, BinaryRecall, BinaryHammingDistance\n",
    "\n",
    "# Import transformer model\n",
    "from Transformer_Archs.Sparsemax_Enc import TimeseriesTransformer\n",
    "\n",
    "# Clear cuda cache\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option for 5% or 10% attack data\n",
    "option = '15' \n",
    "\n",
    "# Get data loaders\n",
    "train_dataset = torch.load('./Preprocessed_data/train_dataset_{}.pt'.format(option), weights_only=False)\n",
    "train_config = torch.load('./Preprocessed_data/train_config_{}.pt'.format(option), weights_only=False)\n",
    "train_loader = DataLoader(train_dataset, **train_config)\n",
    "\n",
    "val_dataset = torch.load('./Preprocessed_data/val_dataset_{}.pt'.format(option), weights_only=False)\n",
    "val_config = torch.load('./Preprocessed_data/val_config_{}.pt'.format(option), weights_only=False)\n",
    "val_loader = DataLoader(val_dataset, **val_config)\n",
    "\n",
    "test_dataset = torch.load('./Preprocessed_data/test_dataset_{}.pt'.format(option), weights_only=False)\n",
    "test_config = torch.load('./Preprocessed_data/test_config_{}.pt'.format(option), weights_only=False)\n",
    "test_loader = DataLoader(test_dataset, **test_config)\n",
    "\n",
    "# Set feautures and target size\n",
    "num_features = 373\n",
    "out_features = 20\n",
    "seq_len = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup hyperparameter\n",
    "d_model = 512\n",
    "nhead = 4\n",
    "num_encoder_layers = 4\n",
    "dim_feedforward = 512\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Initialize the model\n",
    "# Input style: [input_feature_size, output_feature_size, d_model, nhead, num_encoder_layers, dim_feedforward]\n",
    "model = TimeseriesTransformer(num_features, out_features, d_model, nhead, num_encoder_layers, dim_feedforward).to(device)\n",
    "\n",
    "# Training loop (simplified)\n",
    "criterion=nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr= 1e-4) #0.001, 5e-4, 1e-3\n",
    "\n",
    "# Define the learning rate scheduler (for example, exponential decay)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, min_delta=0):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How many epochs to wait after last time validation loss improved.\n",
    "            min_delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.best_loss = None\n",
    "        self.counter = 0\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "        elif val_loss > self.best_loss - self.min_delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch, metric):\n",
    "    model.train()\n",
    "    accuracy_list, loss_list = [], []\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        data = data.permute(1, 0, 2)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        accuracy = metric(output, target)\n",
    "        accuracy_list.append(accuracy.item())\n",
    "        loss_list.append(loss.item())\n",
    "        \n",
    "    print(\"Train Epoch: {} - Training Loss: {:.5f} Training accuracy: {:.3f}%\".format(epoch,np.mean(loss_list) ,np.mean(accuracy_list)*100))\n",
    "\n",
    "    return np.mean(accuracy_list)*100, np.mean(loss_list)\n",
    "\n",
    "def Validation(model, device, valid_loader, epoch, metric):\n",
    "    model.eval()\n",
    "    accuracy_list, loss_list = [], []\n",
    "    for batch_idx, (data, target) in enumerate(valid_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        data = data.permute(1, 0, 2)\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        accuracy = metric(output, target)\n",
    "        accuracy_list.append(accuracy.item())\n",
    "        loss_list.append(loss.item())\n",
    "        \n",
    "    print(\"Valid Epoch: {} - Validation Loss: {:.5f} Validation accuracy: {:.3f}%\".format(epoch,np.mean(loss_list) ,np.mean(accuracy_list)*100))\n",
    "\n",
    "    return np.mean(accuracy_list)*100, np.mean(loss_list)             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the early stopping mechanism\n",
    "early_stopping = EarlyStopping(patience=10, min_delta=0.0001)\n",
    "train_acc_list, val_acc_list = [], []\n",
    "train_loss_list, val_loss_list = [], []\n",
    "\n",
    "metric = BinaryAccuracy().to(device)\n",
    "\n",
    "# Train the model\n",
    "epochs = 150\n",
    "for epoch in range(1, epochs + 1):\n",
    "        train_acc, train_loss = train( model, device, train_loader, optimizer, epoch, metric)\n",
    "        Val_acc, Val_loss = Validation(model, device, val_loader, epoch, metric)\n",
    "        train_acc_list.append(train_acc), val_acc_list.append(Val_acc)\n",
    "        train_loss_list.append(train_loss), val_loss_list.append(Val_loss)\n",
    "        scheduler.step(train_loss)\n",
    "        early_stopping(train_loss)\n",
    "        if early_stopping.early_stop:\n",
    "             print(\"Early stopping triggered. Stopping training.\")\n",
    "             break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save training loss and accuracy\n",
    "np.save('./Final_models/Sparsemax/train_loss_sparsemax_{}.npy'.format(option), np.array(train_loss_list))\n",
    "np.save('./Final_models/Sparsemax/train_accuracy_sparsemax_{}.npy'.format(option), np.array(train_acc_list))\n",
    "np.save('./Final_models//Sparsemax/val_loss_sparsemax_{}.npy'.format(option), np.array(val_loss_list))\n",
    "np.save('./Final_models/Sparsemax/val_accuracy_sparsemax_{}.npy'.format(option), np.array(val_acc_list))\n",
    "torch.save(model.state_dict(), \"./Final_models/Sparsemax/transformer_sparsemax_{}.pth\".format(option))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup hyperparameter\n",
    "d_model = 512\n",
    "nhead = 4\n",
    "num_encoder_layers = 4\n",
    "dim_feedforward = 512\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Initialize the model\n",
    "# Input style: [input_feature_size, output_feature_size, d_model, nhead, num_encoder_layers, dim_feedforward]\n",
    "model = TimeseriesTransformer(num_features, out_features, d_model, nhead, num_encoder_layers, dim_feedforward).to(device)\n",
    "\n",
    "# Training loop (simplified)\n",
    "criterion=nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Load model weights\n",
    "model.load_state_dict(torch.load(\"./Final_models/Sparsemax/transformer_sparsemax_{}.pth\".format(option), weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "accuracy_list = []\n",
    "with torch.no_grad():\n",
    "    data, target = next(iter(test_loader))\n",
    "    data, target = data.to(device), target.to(device)\n",
    "    data = data.permute(1, 0, 2)\n",
    "    output = model(data)\n",
    "    test_loss += criterion(output, target).item()  # sum up batch loss\n",
    "    accuracy = metric(output, target).item()\n",
    "    accuracy_list.append(accuracy)\n",
    "\n",
    "    print('Test set: Loss: {:.6f}, Accuracy: {:.3f}%\\n'.format(\n",
    "        test_loss, accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics\n",
    "avg_precision = BinaryAveragePrecision().to(device)\n",
    "f1 = BinaryF1Score().to(device)\n",
    "precision = BinaryPrecision().to(device)\n",
    "recall = BinaryRecall().to(device)\n",
    "hamming = BinaryHammingDistance().to(device)\n",
    "\n",
    "# Calculate metrics\n",
    "avg_precision_score = avg_precision(output, target.int()).item()\n",
    "f1_score = f1(output, target).item()\n",
    "precision_score = precision(output, target).item()\n",
    "recall_score = recall(output, target).item()\n",
    "hamming_score = hamming(output, target).item()\n",
    "\n",
    "# Print metrics\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Average Precision: {avg_precision_score}\")\n",
    "print(f\"F1 Score: {f1_score}\")\n",
    "print(f\"Precision: {precision_score}\")\n",
    "print(f\"Recall: {recall_score}\")\n",
    "print(f\"Hamming Distance: {hamming_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot avg accuracy and loss\n",
    "plt.grid()\n",
    "plt.plot(train_acc_list, label=r\"Training accuracy\")\n",
    "plt.plot(val_acc_list, label=r\"Validation accuracy\")\n",
    "plt.xlabel(r\"Epoch $\\longrightarrow$\")\n",
    "plt.ylabel(r\"Accuracy $\\longrightarrow$\");\n",
    "plt.legend()\n",
    "plt.title(r\"Average accuracy per epoch - Softmax\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot avg loss\n",
    "plt.grid()\n",
    "plt.plot(train_loss_list, label=r\"Training loss\")\n",
    "plt.plot(val_loss_list, label=r\"Validation loss\")\n",
    "plt.xlabel(r\"Epoch $\\longrightarrow$\")\n",
    "plt.ylabel(r\"Loss $\\longrightarrow$\");\n",
    "plt.legend(loc='best');\n",
    "plt.title(r\"Average loss per epoch - Softmax\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
